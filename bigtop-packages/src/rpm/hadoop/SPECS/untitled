
LOAD 'HDFS'.'/usr/test' FORMAT 'CSV' OPTIONS('header'='true') AS T WHERE A=1 AND B=2;

LOAD 'ADLS'.'/usr/test' FORMAT 'JSON' AS T WHERE A=1 AND B=2;

LOAD 'S3'.'/usr/test' FORMAT 'PARQUET' AS T WHERE A=1 AND B=2;

LOAD 'LOCAL'.'/usr/test' FORMAT 'ORC' AS T WHERE A=1 AND B=2;


LOAD 'MYSQL' OPTIONS ('host'='node1','port'='3306','dbtable'='default.t1','user'='admin', 'password'='123') AS T1 WHERE A=1 AND B=2;

LOAD 'HBASE' OPTIONS ('host'='node1','port'='3306','dbtable'='default.t1','user'='admin', 'password'='123') AS T1 WHERE A=1 AND B=2;

LOAD 'ES' OPTIONS ('host'='node1','port'='3306','dbtable'='default.t1','user'='admin', 'password'='123') AS T1 WHERE A=1 AND B=2;

---------------

Spark SQL/Stream SQL + TVF

select * from (select * from T join F on T.ID=F.FID) AS T1;

---------------

SAVE T1 TO 'LOCAL'.'/usr/a' FORMAT 'PARQUET' PARTITION BY COL2;

SAVE APPEND T1 TO 'HDFS'.'/usr/a' FORMAT 'PARQUET' PARTITION BY COL2;

SAVE OVERWRITE T1 TO 'S3'.'/usr/a' FORMAT 'PARQUET' OPTIONS ('host'='node1') PARTITION BY COL2;

SAVE T1 TO 'MYSQL' OPTIONS ('host'='node1','port'='3306','dbtable'='default.t1','user'='admin', 'password'='123')

SAVE APPEND T1 TO 'ORACLE' OPTIONS ('host'='node1','port'='3306','dbtable'='ora1.a1','user'='admin', 'password'='123')

SAVE OVERWRITE T1 TO 'ORACLE' OPTIONS ('host'='node1','port'='3306','dbtable'='ora1.a1','user'='admin', 'password'='123')



*** WARNING: identical binaries are copied, not linked:
        /usr/jdp/3.1.0.0-108/hadoop/bin/container-executor
   and  /usr/jdp/3.1.0.0-108/hadoop-yarn/bin/container-executor

   